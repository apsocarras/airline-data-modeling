{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Create data model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Model](img/data_model2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: \n",
    "1. _Load dimensions_  \n",
    "\n",
    "   a. Create big query client, dataset, and table schema\n",
    "\n",
    "   b. Create tables\n",
    "   \n",
    "   c. Read and transform dimension dataframes from source data\n",
    "\n",
    "   d. Load to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][2023-01-06 18:01:19,514][2441037682:0069] : Creating bigquery client\n",
      "[INFO ][2023-01-06 18:01:19,518][2441037682:0072] : Setup Completed\n",
      "[INFO ][2023-01-06 18:01:20,099][2441037682:0080] : Created dataset: electric-glyph-372116:airlines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import List\n",
    "from google.cloud import bigquery \n",
    " \n",
    "DATA_DIR = \"../data/\"\n",
    "DEFAULT_TICKET_FILE = os.path.join(DATA_DIR, \"tickets.json\")\n",
    "PROJECT_NAME = \"electric-glyph-372116\"\n",
    "DATASET_NAME = \"airlines\"\n",
    " \n",
    "# **** TABLE SCHEMAS ****\n",
    "## Dimension Tables\n",
    "TABLE_METADATA = {\n",
    "   'passengers_d': {\n",
    "       'table_name': 'passengers_d',\n",
    "       'schema': [\n",
    "           bigquery.SchemaField('sk_pass_id', 'STRING', mode='REQUIRED'),\n",
    "           bigquery.SchemaField('email', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('first_name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('last_name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('gender', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('birth_date', 'DATE', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('street', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('city', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('zip', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('state', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('start_date', 'DATE', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('end_date', 'DATE', mode='NULLABLE')\n",
    "       ]\n",
    "   }, 'airlines_d': {\n",
    "       'table_name': 'airlines_d',\n",
    "       'schema': [\n",
    "           bigquery.SchemaField('airline_id', 'STRING', mode='REQUIRED'),\n",
    "           bigquery.SchemaField('name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('icao', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('callsign', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('country', 'STRING', mode='NULLABLE')\n",
    "       ]\n",
    "   },  'airports_d': {\n",
    "       'table_name': 'airports_d',\n",
    "       'schema': [\n",
    "           bigquery.SchemaField('airport_id', 'STRING', mode='REQUIRED'),\n",
    "           bigquery.SchemaField('name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('city', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('country', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('icao', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('latitude', 'FLOAT', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('longitude', 'FLOAT', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('altitude', 'INTEGER', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('tz_timezone', 'STRING', mode='NULLABLE'),\n",
    "       ]\n",
    "   }\n",
    "}\n",
    "\n",
    "# **** SETUP LOGGING ****\n",
    "# setup logging and logger\n",
    "logging.basicConfig(            # setting up the root logger\n",
    "   format='[%(levelname)-5s][%(asctime)s][%(module)s:%(lineno)04d] : %(message)s',\n",
    "   level=logging.INFO,\n",
    "   stream=sys.stdout\n",
    ")\n",
    "logger: logging.Logger = logging.getLogger('root')      # alias the root logger as `logger`\n",
    "logger.setLevel(logging.DEBUG)                 # programmatically reassign the logging level\n",
    "\n",
    " \n",
    "# **** BIGQUERY CLIENT ****\n",
    "logger.debug(f\"Creating bigquery client\")\n",
    "client = bigquery.Client()\n",
    "\n",
    "logger.info(f\"Setup Completed\")\n",
    "\n",
    "# **** CREATE DATASET (IF NEEDED) ****\n",
    "dataset_id = f\"{PROJECT_NAME}.{DATASET_NAME}\"\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = \"US\"\n",
    "dataset = client.create_dataset(dataset, exists_ok=True)\n",
    "\n",
    "logger.info(f\"Created dataset: {dataset.full_dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][2023-01-06 18:01:20,128][2989774279:0002] : Creating tables:\n",
      "[INFO ][2023-01-06 18:01:20,408][2989774279:0012] : Did not create table passengers_d. Already exist?\n",
      "\tsk_pass_id\tSTRING\n",
      "\tfirst_name\tSTRING\n",
      "\tlast_name\tSTRING\n",
      "\tgender\tSTRING\n",
      "\tbirth_date\tDATE\n",
      "\temail\tSTRING\n",
      "\tstreet\tSTRING\n",
      "\tcity\tSTRING\n",
      "\tstate\tSTRING\n",
      "\tzip\tSTRING\n",
      "\tstart_date\tDATE\n",
      "\tend_date\tDATE\n",
      "\n",
      "\n",
      "[INFO ][2023-01-06 18:01:20,791][2989774279:0012] : Did not create table airlines_d. Already exist?\n",
      "\tairline_id\tSTRING\n",
      "\tname\tSTRING\n",
      "\ticao\tSTRING\n",
      "\tcallsign\tSTRING\n",
      "\tcountry\tSTRING\n",
      "\n",
      "\n",
      "[INFO ][2023-01-06 18:01:21,124][2989774279:0012] : Did not create table airports_d. Already exist?\n",
      "\tairport_id\tSTRING\n",
      "\tname\tSTRING\n",
      "\tcity\tSTRING\n",
      "\tcountry\tSTRING\n",
      "\ticao\tSTRING\n",
      "\tlatitude\tFLOAT\n",
      "\tlongitude\tFLOAT\n",
      "\taltitude\tINTEGER\n",
      "\ttz_timezone\tSTRING\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# **** CREATE TABLES ****\n",
    "logger.debug(f\"Creating tables:\")\n",
    "\n",
    "for table_id in TABLE_METADATA:\n",
    "  full_table_id = f\"{PROJECT_NAME}.{DATASET_NAME}.{table_id}\"\n",
    "  schema = TABLE_METADATA[f'{table_id}']['schema']\n",
    "  table = bigquery.Table(full_table_id, schema = schema)\n",
    "  try:\n",
    "    client.create_table(table) \n",
    "    logger.info(f\"Created table: {table_id}\")\n",
    "  except:\n",
    "    logger.info(f\"Did not create table {table_id}. Already exist?\")\n",
    "  # List table Schema\n",
    "  table_ref = client.get_table(table)\n",
    "  for column in table_ref.schema:\n",
    "    print(f\"\\t{column.name}\\t{column.field_type}\") \n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** READ/TRANSFORM DIMENSION DATA ****\n",
    "import json\n",
    "import datetime as dt\n",
    "\n",
    "## Read JSON Row File (Nested)\n",
    "output = []\n",
    "with open(\"data/tickets.json\", \"r\") as json_file:\n",
    "  for line in json_file:\n",
    "    row = json.loads(line.strip())\n",
    "    output.append(row)\n",
    "df = pd.json_normalize(output)\n",
    " \n",
    "# Extract unnested columns and remove prefixes\n",
    "def extractUnnested(prefix):\n",
    "  extract = df.filter(regex = prefix)\n",
    "  extract.columns = [col.split('.')[1] for col in extract.columns]\n",
    "  return extract\n",
    "\n",
    "airline_df = extractUnnested('airline\\.')\n",
    "pass_df = extractUnnested('passenger\\.')\n",
    "origin_df = extractUnnested('origin\\.')\n",
    "dest_df = extractUnnested('destination\\.')\n",
    "airports_df = origin_df.append(dest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension 1: Airlines \n",
    "airline_df.set_index('iata', inplace=True)\n",
    "airline_df.index.rename('airline_id', inplace=True)\n",
    "airline_df = airline_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension 2: Airports\n",
    "airports_df.set_index('iata', inplace=True)\n",
    "airports_df.index.rename('airport_id', inplace=True)\n",
    "airports_df = airports_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension 3: Passengers\n",
    "import shortuuid as su\n",
    "from datetime import date\n",
    "\n",
    "pass_df = pass_df.drop_duplicates()\n",
    "pass_df['sk_pass_id'] = [su.uuid() for _ in range(len(pass_df.index))]\n",
    "pass_df['start_date'] = date.today()\n",
    "pass_df['end_date'] = None\n",
    "pass_df['birth_date'] = pd.to_datetime(pass_df['birth_date'])\n",
    "pass_df.set_index('sk_pass_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO ][2023-01-06 18:01:21,677][600813873:0030] : loading table: 'electric-glyph-372116.airlines.airlines_d'\n",
      "[INFO ][2023-01-06 18:01:24,605][600813873:0035] : loaded 48 rows into electric-glyph-372116:airlines.airlines_d\n",
      "[INFO ][2023-01-06 18:01:24,606][600813873:0030] : loading table: 'electric-glyph-372116.airlines.airports_d'\n",
      "[INFO ][2023-01-06 18:01:29,130][600813873:0035] : loaded 392 rows into electric-glyph-372116:airlines.airports_d\n",
      "[INFO ][2023-01-06 18:01:29,131][600813873:0030] : loading table: 'electric-glyph-372116.airlines.passengers_d'\n",
      "[INFO ][2023-01-06 18:01:32,646][600813873:0035] : loaded 32 rows into electric-glyph-372116:airlines.passengers_d\n"
     ]
    }
   ],
   "source": [
    "# **** LOADING DIMENSION TABLES  ****\n",
    "def load_table(\n",
    "    df: pd.DataFrame, \n",
    "    client: bigquery.Client, \n",
    "    table_name: str, \n",
    "    schema: List[bigquery.SchemaField], \n",
    "    create_disposition: str = 'CREATE_IF_NEEDED', \n",
    "    write_disposition: str = 'WRITE_TRUNCATE'\n",
    "    ) -> None:\n",
    "    \"\"\"load dataframe into bigquery table\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to load\n",
    "        client (bigquery.Client): bigquery client\n",
    "        table_name (str): full table name including project and dataset id\n",
    "        schema (List[bigquery.SchemaField]): table schema with data types\n",
    "        create_disposition (str, optional): create table disposition. Defaults to 'CREATE_IF_NEEDED'.\n",
    "        write_disposition (str, optional): overwrite table disposition. Defaults to 'WRITE_TRUNCATE'.\n",
    "    \"\"\"\n",
    "    # *** run some checks ***\n",
    "    # test table name to be full table name including project and dataset name. It must contain to dots\n",
    "    assert len(table_name.split('.')) == 3, f\"Table name must be a full bigquery table name including project and dataset id: '{table_name}'\"\n",
    "    # setup bigquery load job:\n",
    "    #  create table if needed, replace rows, define the table schema\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        create_disposition=create_disposition,\n",
    "        write_disposition=write_disposition,\n",
    "        schema=schema\n",
    "    )\n",
    "    logger.info(f\"loading table: '{table_name}'\")\n",
    "    job = client.load_table_from_dataframe(df, destination=table_name, job_config=job_config)\n",
    "    job.result()        # wait for the job to finish\n",
    "    # get the resulting table\n",
    "    table = client.get_table(table_name)\n",
    "    logger.info(f\"loaded {table.num_rows} rows into {table.full_table_id}\")\n",
    "\n",
    "## Airlines Dimension\n",
    "# load to bigquery\n",
    "table_name = f\"{PROJECT_NAME}.{DATASET_NAME}.{TABLE_METADATA['airlines_d']['table_name']}\"\n",
    "schema = TABLE_METADATA['airlines_d']['schema']\n",
    "load_table(airline_df, client, table_name, schema)\n",
    "\n",
    "## Airports Dimension\n",
    "# load to bigquery\n",
    "table_name = f\"{PROJECT_NAME}.{DATASET_NAME}.{TABLE_METADATA['airports_d']['table_name']}\"\n",
    "schema = TABLE_METADATA['airports_d']['schema']\n",
    "load_table(airports_df, client, table_name, schema)\n",
    "\n",
    "## Passengers Dimension\n",
    "# load to bigquery\n",
    "table_name = f\"{PROJECT_NAME}.{DATASET_NAME}.{TABLE_METADATA['passengers_d']['table_name']}\"\n",
    "schema = TABLE_METADATA['passengers_d']['schema']\n",
    "load_table(pass_df, client, table_name, schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. _Load Facts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/deb-projects/airline-data-modeling/venv/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "tickets_df = df[['eticket_num', \n",
    "'confirmation', \n",
    "'ticket_date',\n",
    "'passenger.email', # use to lookup sk_pass_id in pass_df\n",
    "'price', \n",
    "'seat', \n",
    "'airline.iata', \n",
    "'origin.iata', \n",
    "'destination.iata'\n",
    "]]\n",
    "\n",
    "tickets_df.rename(columns={\n",
    "  'passenger.email':'email', \n",
    "  'airline.iata':'airline_id', \n",
    "  'origin.iata':'origin_id',\n",
    "  'destination.iata':'dest_id'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: db-dtypes in ./venv/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: numpy<2.0dev,>=1.16.6 in ./venv/lib/python3.7/site-packages (from db-dtypes) (1.21.6)\n",
      "Requirement already satisfied: pandas<2.0dev,>=0.24.2 in ./venv/lib/python3.7/site-packages (from db-dtypes) (1.3.5)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in ./venv/lib/python3.7/site-packages (from db-dtypes) (10.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.7/site-packages (from db-dtypes) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./venv/lib/python3.7/site-packages (from packaging>=17.0->db-dtypes) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./venv/lib/python3.7/site-packages (from pandas<2.0dev,>=0.24.2->db-dtypes) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./venv/lib/python3.7/site-packages (from pandas<2.0dev,>=0.24.2->db-dtypes) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas<2.0dev,>=0.24.2->db-dtypes) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install db-dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eticket_num</th>\n",
       "      <th>confirmation</th>\n",
       "      <th>ticket_date</th>\n",
       "      <th>price</th>\n",
       "      <th>seat</th>\n",
       "      <th>airline_id</th>\n",
       "      <th>origin_id</th>\n",
       "      <th>dest_id</th>\n",
       "      <th>sk_pass_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>498-938211-0795</td>\n",
       "      <td>ZVFDC4</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>723.42</td>\n",
       "      <td>31I</td>\n",
       "      <td>MU</td>\n",
       "      <td>YUL</td>\n",
       "      <td>MDW</td>\n",
       "      <td>iX9KXJhuMrsEgn3sskLYqe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>858-807236-9962</td>\n",
       "      <td>C1V041</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>329.06</td>\n",
       "      <td>33B</td>\n",
       "      <td>AT</td>\n",
       "      <td>EZE</td>\n",
       "      <td>LPA</td>\n",
       "      <td>iX9KXJhuMrsEgn3sskLYqe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670-168600-5273</td>\n",
       "      <td>36TZ1W</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>696.82</td>\n",
       "      <td>26E</td>\n",
       "      <td>MW</td>\n",
       "      <td>XMN</td>\n",
       "      <td>BUR</td>\n",
       "      <td>iX9KXJhuMrsEgn3sskLYqe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>947-437384-1202</td>\n",
       "      <td>P06H2N</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>218.32</td>\n",
       "      <td>13C</td>\n",
       "      <td>AF</td>\n",
       "      <td>FTE</td>\n",
       "      <td>VCE</td>\n",
       "      <td>iX9KXJhuMrsEgn3sskLYqe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>471-738372-4392</td>\n",
       "      <td>438YR7</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>889.04</td>\n",
       "      <td>27D</td>\n",
       "      <td>DD</td>\n",
       "      <td>RNO</td>\n",
       "      <td>TAO</td>\n",
       "      <td>iX9KXJhuMrsEgn3sskLYqe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>760-206124-8120</td>\n",
       "      <td>NHFJK3</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>372.00</td>\n",
       "      <td>7C</td>\n",
       "      <td>MF</td>\n",
       "      <td>SJC</td>\n",
       "      <td>VIX</td>\n",
       "      <td>JAfGaQxsj3orh8aeVhnuuB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>553-043261-6620</td>\n",
       "      <td>B74278</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>626.87</td>\n",
       "      <td>28E</td>\n",
       "      <td>MF</td>\n",
       "      <td>JJN</td>\n",
       "      <td>LAS</td>\n",
       "      <td>JAfGaQxsj3orh8aeVhnuuB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>531-358995-2051</td>\n",
       "      <td>440THN</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>523.76</td>\n",
       "      <td>12H</td>\n",
       "      <td>MW</td>\n",
       "      <td>GOI</td>\n",
       "      <td>MSP</td>\n",
       "      <td>JAfGaQxsj3orh8aeVhnuuB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>269-794782-2875</td>\n",
       "      <td>B87BMW</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>349.08</td>\n",
       "      <td>21I</td>\n",
       "      <td>HO</td>\n",
       "      <td>LIM</td>\n",
       "      <td>ORY</td>\n",
       "      <td>JAfGaQxsj3orh8aeVhnuuB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>455-159360-2720</td>\n",
       "      <td>M1TJ61</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>779.06</td>\n",
       "      <td>16E</td>\n",
       "      <td>SJ</td>\n",
       "      <td>GRR</td>\n",
       "      <td>ZAG</td>\n",
       "      <td>JAfGaQxsj3orh8aeVhnuuB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4096 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          eticket_num confirmation ticket_date   price seat airline_id  \\\n",
       "0     498-938211-0795       ZVFDC4  2022-03-23  723.42  31I         MU   \n",
       "1     858-807236-9962       C1V041  2022-03-22  329.06  33B         AT   \n",
       "2     670-168600-5273       36TZ1W  2022-03-23  696.82  26E         MW   \n",
       "3     947-437384-1202       P06H2N  2022-03-24  218.32  13C         AF   \n",
       "4     471-738372-4392       438YR7  2022-03-22  889.04  27D         DD   \n",
       "...               ...          ...         ...     ...  ...        ...   \n",
       "4091  760-206124-8120       NHFJK3  2022-03-23  372.00   7C         MF   \n",
       "4092  553-043261-6620       B74278  2022-03-24  626.87  28E         MF   \n",
       "4093  531-358995-2051       440THN  2022-03-23  523.76  12H         MW   \n",
       "4094  269-794782-2875       B87BMW  2022-03-23  349.08  21I         HO   \n",
       "4095  455-159360-2720       M1TJ61  2022-03-21  779.06  16E         SJ   \n",
       "\n",
       "     origin_id dest_id              sk_pass_id  \n",
       "0          YUL     MDW  iX9KXJhuMrsEgn3sskLYqe  \n",
       "1          EZE     LPA  iX9KXJhuMrsEgn3sskLYqe  \n",
       "2          XMN     BUR  iX9KXJhuMrsEgn3sskLYqe  \n",
       "3          FTE     VCE  iX9KXJhuMrsEgn3sskLYqe  \n",
       "4          RNO     TAO  iX9KXJhuMrsEgn3sskLYqe  \n",
       "...        ...     ...                     ...  \n",
       "4091       SJC     VIX  JAfGaQxsj3orh8aeVhnuuB  \n",
       "4092       JJN     LAS  JAfGaQxsj3orh8aeVhnuuB  \n",
       "4093       GOI     MSP  JAfGaQxsj3orh8aeVhnuuB  \n",
       "4094       LIM     ORY  JAfGaQxsj3orh8aeVhnuuB  \n",
       "4095       GRR     ZAG  JAfGaQxsj3orh8aeVhnuuB  \n",
       "\n",
       "[4096 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "  sk_pass_id, \n",
    "  email\n",
    "FROM {PROJECT_NAME}.{DATASET_NAME}.passengers_d\n",
    "\"\"\"\n",
    "pdf = client.query(query).to_dataframe()\n",
    "tickets_df = pd.merge(tickets_df, pdf, on = \"email\").drop(\"email\", axis=1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eb925e235345ffe75b6938749d5e2df8d24cab43adbaf1e5ac7fd251492b6fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
