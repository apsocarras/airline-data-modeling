{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Create data model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Model](img/data_model2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: \n",
    "1. _Load dimensions_  \n",
    "\n",
    "   a. Create big query client, dataset, and table schema\n",
    "\n",
    "   b. Create tables\n",
    "   \n",
    "   c. Read and transform dimension dataframes from source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][2023-01-06 16:15:20,729][3829676985:0068] : Creating bigquery client\n",
      "[INFO ][2023-01-06 16:15:20,734][3829676985:0071] : Setup Completed\n",
      "[INFO ][2023-01-06 16:15:21,392][3829676985:0079] : Created dataset: electric-glyph-372116:airlines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import List\n",
    "from google.cloud import bigquery \n",
    " \n",
    "DATA_DIR = \"../data/\"\n",
    "DEFAULT_TICKET_FILE = os.path.join(DATA_DIR, \"tickets.json\")\n",
    "PROJECT_NAME = \"electric-glyph-372116\"\n",
    "DATASET_NAME = \"airlines\"\n",
    " \n",
    "# **** TABLE SCHEMAS ****\n",
    "## Dimension Tables\n",
    "TABLE_METADATA = {\n",
    "   'passengers_d': {\n",
    "       'table_name': 'passengers_d',\n",
    "       'schema': [\n",
    "           bigquery.SchemaField('sk_pass_id', 'STRING', mode='REQUIRED'),\n",
    "           bigquery.SchemaField('email', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('first_name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('last_name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('gender', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('birth_date', 'DATE', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('street', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('city', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('zip', 'INTEGER', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('state', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('start_date', 'DATE', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('end_date', 'DATE', mode='NULLABLE')\n",
    "       ]\n",
    "   }, 'airlines_d': {\n",
    "       'table_name': 'airlines_d',\n",
    "       'schema': [\n",
    "           bigquery.SchemaField('airline_id', 'STRING', mode='REQUIRED'),\n",
    "           bigquery.SchemaField('name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('icao', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('callsign', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('country', 'STRING', mode='NULLABLE')\n",
    "       ]\n",
    "   },  'airports_d': {\n",
    "       'table_name': 'airports_d',\n",
    "       'schema': [\n",
    "           bigquery.SchemaField('airport_id', 'STRING', mode='REQUIRED'),\n",
    "           bigquery.SchemaField('name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('city', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('country', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('icao', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('latitude', 'FLOAT', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('longitude', 'FLOAT', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('altitude', 'INTEGER', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('tz_timezone', 'STRING', mode='NULLABLE'),\n",
    "       ]\n",
    "   }\n",
    "}\n",
    "\n",
    "# **** SETUP LOGGING ****\n",
    "# setup logging and logger\n",
    "logging.basicConfig(            # setting up the root logger\n",
    "   format='[%(levelname)-5s][%(asctime)s][%(module)s:%(lineno)04d] : %(message)s',\n",
    "   level=logging.INFO,\n",
    "   stream=sys.stdout\n",
    ")\n",
    "logger: logging.Logger = logging.getLogger('root')      # alias the root logger as `logger`\n",
    "logger.setLevel(logging.DEBUG)                 # programmatically reassign the logging level\n",
    "\n",
    " \n",
    "# **** BIGQUERY CLIENT ****\n",
    "logger.debug(f\"Creating bigquery client\")\n",
    "client = bigquery.Client()\n",
    "\n",
    "logger.info(f\"Setup Completed\")\n",
    "\n",
    "# **** CREATE DATASET (IF NEEDED) ****\n",
    "dataset_id = f\"{PROJECT_NAME}.{DATASET_NAME}\"\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = \"US\"\n",
    "dataset = client.create_dataset(dataset, exists_ok=True)\n",
    "\n",
    "logger.info(f\"Created dataset: {dataset.full_dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][2023-01-06 16:18:36,204][2989774279:0002] : Creating tables:\n",
      "[INFO ][2023-01-06 16:18:36,467][2989774279:0012] : Did not create table passengers_d. Already exist?\n",
      "\tsk_pass_id\tSTRING\n",
      "\temail\tSTRING\n",
      "\tfirst_name\tSTRING\n",
      "\tlast_name\tSTRING\n",
      "\tgender\tSTRING\n",
      "\tbirth_date\tDATE\n",
      "\tstreet\tSTRING\n",
      "\tcity\tSTRING\n",
      "\tzip\tINTEGER\n",
      "\tstate\tSTRING\n",
      "\tstart_date\tDATE\n",
      "\tend_date\tDATE\n",
      "\n",
      "\n",
      "[INFO ][2023-01-06 16:18:36,843][2989774279:0012] : Did not create table airlines_d. Already exist?\n",
      "\tairline_id\tSTRING\n",
      "\tname\tSTRING\n",
      "\ticao\tSTRING\n",
      "\tcallsign\tSTRING\n",
      "\tcountry\tSTRING\n",
      "\n",
      "\n",
      "[INFO ][2023-01-06 16:18:37,183][2989774279:0012] : Did not create table airports_d. Already exist?\n",
      "\tairport_id\tSTRING\n",
      "\tname\tSTRING\n",
      "\tcity\tSTRING\n",
      "\tcountry\tSTRING\n",
      "\ticao\tSTRING\n",
      "\tlatitude\tFLOAT\n",
      "\tlongitude\tFLOAT\n",
      "\taltitude\tINTEGER\n",
      "\ttz_timezone\tSTRING\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# **** CREATE TABLES ****\n",
    "logger.debug(f\"Creating tables:\")\n",
    "\n",
    "for table_id in TABLE_METADATA:\n",
    "  full_table_id = f\"{PROJECT_NAME}.{DATASET_NAME}.{table_id}\"\n",
    "  schema = TABLE_METADATA[f'{table_id}']['schema']\n",
    "  table = bigquery.Table(full_table_id, schema = schema)\n",
    "  try:\n",
    "    client.create_table(table) \n",
    "    logger.info(f\"Created table: {table_id}\")\n",
    "  except:\n",
    "    logger.info(f\"Did not create table {table_id}. Already exist?\")\n",
    "  # List table Schema\n",
    "  table_ref = client.get_table(table)\n",
    "  for column in table_ref.schema:\n",
    "    print(f\"\\t{column.name}\\t{column.field_type}\") \n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** READ/TRANSFORM DATA ****\n",
    "import json\n",
    "import datetime as dt\n",
    "\n",
    "## Read JSON Row File (Nested)\n",
    "output = []\n",
    "with open(\"data/tickets.json\", \"r\") as json_file:\n",
    "  for line in json_file:\n",
    "    row = json.loads(line.strip())\n",
    "    output.append(row)\n",
    "df = pd.json_normalize(output)\n",
    " \n",
    "# Extract unnested columns and remove prefixes\n",
    "def extractUnnested(prefix):\n",
    "  extract = df.filter(regex = prefix)\n",
    "  extract.columns = [col.split('.')[1] for col in extract.columns]\n",
    "  return extract\n",
    "\n",
    "airline_df = extractUnnested('airline\\.')\n",
    "pass_df = extractUnnested('passenger\\.')\n",
    "origin_df = extractUnnested('origin\\.')\n",
    "dest_df = extractUnnested('destination\\.')\n",
    "airports_df = origin_df.append(dest_df)\n",
    "\n",
    "# Extract non-nested columns\n",
    "tickets_df = df.iloc[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension 1: Airlines \n",
    "airline_df.set_index('iata', inplace=True)\n",
    "airline_df.index.rename('airline_id', inplace=True)\n",
    "airline_df = airline_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension 2: Airports\n",
    "airports_df.set_index('iata', inplace=True)\n",
    "airports_df.index.rename('airport_id', inplace=True)\n",
    "airports_df = airports_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension 3: Passengers\n",
    "import shortuuid as su\n",
    "from datetime import date\n",
    "\n",
    "pass_df = pass_df.drop_duplicates()\n",
    "pass_df['sk_pass_id'] = [su.uuid() for _ in range(len(pass_df.index))]\n",
    "pass_df['start_date'] = date.today()\n",
    "pass_df['end_date'] = None\n",
    "pass_df.set_index('sk_pass_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32814/701718642.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSchemaField\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcreate_disposition\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CREATE_IF_NEEDED'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mwrite_disposition\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'WRITE_TRUNCATE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     ) -> None:\n\u001b[1;32m     10\u001b[0m     \"\"\"load dataframe into bigquery table\n",
      "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "# **** LOADING DIMENSION TABLES  ****\n",
    "def load_table(\n",
    "    df: pd.DataFrame, \n",
    "    client: bigquery.Client, \n",
    "    table_name: str, \n",
    "    schema: List[bigquery.SchemaField], \n",
    "    create_disposition: str = 'CREATE_IF_NEEDED', \n",
    "    write_disposition: str = 'WRITE_TRUNCATE'\n",
    "    ) -> None:\n",
    "    \"\"\"load dataframe into bigquery table\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to load\n",
    "        client (bigquery.Client): bigquery client\n",
    "        table_name (str): full table name including project and dataset id\n",
    "        schema (List[bigquery.SchemaField]): table schema with data types\n",
    "        create_disposition (str, optional): create table disposition. Defaults to 'CREATE_IF_NEEDED'.\n",
    "        write_disposition (str, optional): overwrite table disposition. Defaults to 'WRITE_TRUNCATE'.\n",
    "    \"\"\"\n",
    "    # *** run some checks ***\n",
    "    # test table name to be full table name including project and dataset name. It must contain to dots\n",
    "    assert len(table_name.split('.')) == 3, f\"Table name must be a full bigquery table name including project and dataset id: '{table_name}'\"\n",
    "    # setup bigquery load job:\n",
    "    #  create table if needed, replace rows, define the table schema\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        create_disposition=create_disposition,\n",
    "        write_disposition=write_disposition,\n",
    "        schema=schema\n",
    "    )\n",
    "    logger.info(f\"loading table: '{table_name}'\")\n",
    "    job = client.load_table_from_dataframe(df, destination=table_name, job_config=job_config)\n",
    "    job.result()        # wait for the job to finish\n",
    "    # get the resulting table\n",
    "    table = client.get_table(table_name)\n",
    "    logger.info(f\"loaded {table.num_rows} rows into {table.full_table_id}\")\n",
    "\n",
    "## Airlines Dimension\n",
    "# load to bigquery\n",
    "table_name = f\"{PROJECT_NAME}.{DATASET_NAME}.{TABLE_METADATA['airlines_d']['table_name']}\"\n",
    "schema = TABLE_METADATA['airlines_d']['schema']\n",
    "load_table(airline_df, client, table_name, schema)\n",
    "\n",
    "# # load to bigquery\n",
    "# table_name = f\"{PROJECT_NAME}.{DATASET_NAME}.{TABLE_METADATA['receipts_lineitems']['table_name']}\"\n",
    "# schema = TABLE_METADATA['receipts_lineitems']['schema']\n",
    "# load_table(receipts_lineitems, client, table_name, schema)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eb925e235345ffe75b6938749d5e2df8d24cab43adbaf1e5ac7fd251492b6fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
