{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Create data model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Model](img/data_model2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: \n",
    "1. _Load dimensions_  \n",
    "\n",
    "   a. Create big query client, dataset, and table schema\n",
    "\n",
    "   b. Create tables\n",
    "   \n",
    "   c. Read and transform dimension dataframes from source data\n",
    "\n",
    "   d. Load to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][2023-01-06 18:01:19,514][2441037682:0069] : Creating bigquery client\n",
      "[INFO ][2023-01-06 18:01:19,518][2441037682:0072] : Setup Completed\n",
      "[INFO ][2023-01-06 18:01:20,099][2441037682:0080] : Created dataset: electric-glyph-372116:airlines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import List\n",
    "from google.cloud import bigquery \n",
    " \n",
    "DATA_DIR = \"../data/\"\n",
    "DEFAULT_TICKET_FILE = os.path.join(DATA_DIR, \"tickets.json\")\n",
    "PROJECT_NAME = \"electric-glyph-372116\"\n",
    "DATASET_NAME = \"airlines\"\n",
    " \n",
    "# **** TABLE SCHEMAS ****\n",
    "## Dimension Tables\n",
    "TABLE_METADATA = {\n",
    "   'passengers_d': {\n",
    "       'table_name': 'passengers_d',\n",
    "       'schema': [\n",
    "           bigquery.SchemaField('sk_pass_id', 'STRING', mode='REQUIRED'),\n",
    "           bigquery.SchemaField('email', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('first_name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('last_name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('gender', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('birth_date', 'DATE', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('street', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('city', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('zip', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('state', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('start_date', 'DATE', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('end_date', 'DATE', mode='NULLABLE')\n",
    "       ]\n",
    "   }, 'airlines_d': {\n",
    "       'table_name': 'airlines_d',\n",
    "       'schema': [\n",
    "           bigquery.SchemaField('airline_id', 'STRING', mode='REQUIRED'),\n",
    "           bigquery.SchemaField('name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('icao', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('callsign', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('country', 'STRING', mode='NULLABLE')\n",
    "       ]\n",
    "   },  'airports_d': {\n",
    "       'table_name': 'airports_d',\n",
    "       'schema': [\n",
    "           bigquery.SchemaField('airport_id', 'STRING', mode='REQUIRED'),\n",
    "           bigquery.SchemaField('name', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('city', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('country', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('icao', 'STRING', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('latitude', 'FLOAT', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('longitude', 'FLOAT', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('altitude', 'INTEGER', mode='NULLABLE'),\n",
    "           bigquery.SchemaField('tz_timezone', 'STRING', mode='NULLABLE'),\n",
    "       ]\n",
    "   }\n",
    "}\n",
    "\n",
    "# **** SETUP LOGGING ****\n",
    "# setup logging and logger\n",
    "logging.basicConfig(            # setting up the root logger\n",
    "   format='[%(levelname)-5s][%(asctime)s][%(module)s:%(lineno)04d] : %(message)s',\n",
    "   level=logging.INFO,\n",
    "   stream=sys.stdout\n",
    ")\n",
    "logger: logging.Logger = logging.getLogger('root')      # alias the root logger as `logger`\n",
    "logger.setLevel(logging.DEBUG)                 # programmatically reassign the logging level\n",
    "\n",
    " \n",
    "# **** BIGQUERY CLIENT ****\n",
    "logger.debug(f\"Creating bigquery client\")\n",
    "client = bigquery.Client()\n",
    "\n",
    "logger.info(f\"Setup Completed\")\n",
    "\n",
    "# **** CREATE DATASET (IF NEEDED) ****\n",
    "dataset_id = f\"{PROJECT_NAME}.{DATASET_NAME}\"\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = \"US\"\n",
    "dataset = client.create_dataset(dataset, exists_ok=True)\n",
    "\n",
    "logger.info(f\"Created dataset: {dataset.full_dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][2023-01-06 18:01:20,128][2989774279:0002] : Creating tables:\n",
      "[INFO ][2023-01-06 18:01:20,408][2989774279:0012] : Did not create table passengers_d. Already exist?\n",
      "\tsk_pass_id\tSTRING\n",
      "\tfirst_name\tSTRING\n",
      "\tlast_name\tSTRING\n",
      "\tgender\tSTRING\n",
      "\tbirth_date\tDATE\n",
      "\temail\tSTRING\n",
      "\tstreet\tSTRING\n",
      "\tcity\tSTRING\n",
      "\tstate\tSTRING\n",
      "\tzip\tSTRING\n",
      "\tstart_date\tDATE\n",
      "\tend_date\tDATE\n",
      "\n",
      "\n",
      "[INFO ][2023-01-06 18:01:20,791][2989774279:0012] : Did not create table airlines_d. Already exist?\n",
      "\tairline_id\tSTRING\n",
      "\tname\tSTRING\n",
      "\ticao\tSTRING\n",
      "\tcallsign\tSTRING\n",
      "\tcountry\tSTRING\n",
      "\n",
      "\n",
      "[INFO ][2023-01-06 18:01:21,124][2989774279:0012] : Did not create table airports_d. Already exist?\n",
      "\tairport_id\tSTRING\n",
      "\tname\tSTRING\n",
      "\tcity\tSTRING\n",
      "\tcountry\tSTRING\n",
      "\ticao\tSTRING\n",
      "\tlatitude\tFLOAT\n",
      "\tlongitude\tFLOAT\n",
      "\taltitude\tINTEGER\n",
      "\ttz_timezone\tSTRING\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# **** CREATE TABLES ****\n",
    "logger.debug(f\"Creating tables:\")\n",
    "\n",
    "for table_id in TABLE_METADATA:\n",
    "  full_table_id = f\"{PROJECT_NAME}.{DATASET_NAME}.{table_id}\"\n",
    "  schema = TABLE_METADATA[f'{table_id}']['schema']\n",
    "  table = bigquery.Table(full_table_id, schema = schema)\n",
    "  try:\n",
    "    client.create_table(table) \n",
    "    logger.info(f\"Created table: {table_id}\")\n",
    "  except:\n",
    "    logger.info(f\"Did not create table {table_id}. Already exist?\")\n",
    "  # List table Schema\n",
    "  table_ref = client.get_table(table)\n",
    "  for column in table_ref.schema:\n",
    "    print(f\"\\t{column.name}\\t{column.field_type}\") \n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** READ/TRANSFORM DIMENSION DATA ****\n",
    "import json\n",
    "import datetime as dt\n",
    "\n",
    "## Read JSON Row File (Nested)\n",
    "output = []\n",
    "with open(\"data/tickets.json\", \"r\") as json_file:\n",
    "  for line in json_file:\n",
    "    row = json.loads(line.strip())\n",
    "    output.append(row)\n",
    "df = pd.json_normalize(output)\n",
    " \n",
    "# Extract unnested columns and remove prefixes\n",
    "def extractUnnested(prefix):\n",
    "  extract = df.filter(regex = prefix)\n",
    "  extract.columns = [col.split('.')[1] for col in extract.columns]\n",
    "  return extract\n",
    "\n",
    "airline_df = extractUnnested('airline\\.')\n",
    "pass_df = extractUnnested('passenger\\.')\n",
    "origin_df = extractUnnested('origin\\.')\n",
    "dest_df = extractUnnested('destination\\.')\n",
    "airports_df = origin_df.append(dest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension 1: Airlines \n",
    "airline_df.set_index('iata', inplace=True)\n",
    "airline_df.index.rename('airline_id', inplace=True)\n",
    "airline_df = airline_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension 2: Airports\n",
    "airports_df.set_index('iata', inplace=True)\n",
    "airports_df.index.rename('airport_id', inplace=True)\n",
    "airports_df = airports_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension 3: Passengers\n",
    "import shortuuid as su\n",
    "from datetime import date\n",
    "\n",
    "pass_df = pass_df.drop_duplicates()\n",
    "pass_df['sk_pass_id'] = [su.uuid() for _ in range(len(pass_df.index))]\n",
    "pass_df['start_date'] = date.today()\n",
    "pass_df['end_date'] = None\n",
    "pass_df['birth_date'] = pd.to_datetime(pass_df['birth_date'])\n",
    "pass_df.set_index('sk_pass_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO ][2023-01-06 18:01:21,677][600813873:0030] : loading table: 'electric-glyph-372116.airlines.airlines_d'\n",
      "[INFO ][2023-01-06 18:01:24,605][600813873:0035] : loaded 48 rows into electric-glyph-372116:airlines.airlines_d\n",
      "[INFO ][2023-01-06 18:01:24,606][600813873:0030] : loading table: 'electric-glyph-372116.airlines.airports_d'\n",
      "[INFO ][2023-01-06 18:01:29,130][600813873:0035] : loaded 392 rows into electric-glyph-372116:airlines.airports_d\n",
      "[INFO ][2023-01-06 18:01:29,131][600813873:0030] : loading table: 'electric-glyph-372116.airlines.passengers_d'\n",
      "[INFO ][2023-01-06 18:01:32,646][600813873:0035] : loaded 32 rows into electric-glyph-372116:airlines.passengers_d\n"
     ]
    }
   ],
   "source": [
    "# **** LOADING DIMENSION TABLES  ****\n",
    "def load_table(\n",
    "    df: pd.DataFrame, \n",
    "    client: bigquery.Client, \n",
    "    table_name: str, \n",
    "    schema: List[bigquery.SchemaField], \n",
    "    create_disposition: str = 'CREATE_IF_NEEDED', \n",
    "    write_disposition: str = 'WRITE_TRUNCATE'\n",
    "    ) -> None:\n",
    "    \"\"\"load dataframe into bigquery table\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to load\n",
    "        client (bigquery.Client): bigquery client\n",
    "        table_name (str): full table name including project and dataset id\n",
    "        schema (List[bigquery.SchemaField]): table schema with data types\n",
    "        create_disposition (str, optional): create table disposition. Defaults to 'CREATE_IF_NEEDED'.\n",
    "        write_disposition (str, optional): overwrite table disposition. Defaults to 'WRITE_TRUNCATE'.\n",
    "    \"\"\"\n",
    "    # *** run some checks ***\n",
    "    # test table name to be full table name including project and dataset name. It must contain to dots\n",
    "    assert len(table_name.split('.')) == 3, f\"Table name must be a full bigquery table name including project and dataset id: '{table_name}'\"\n",
    "    # setup bigquery load job:\n",
    "    #  create table if needed, replace rows, define the table schema\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        create_disposition=create_disposition,\n",
    "        write_disposition=write_disposition,\n",
    "        schema=schema\n",
    "    )\n",
    "    logger.info(f\"loading table: '{table_name}'\")\n",
    "    job = client.load_table_from_dataframe(df, destination=table_name, job_config=job_config)\n",
    "    job.result()        # wait for the job to finish\n",
    "    # get the resulting table\n",
    "    table = client.get_table(table_name)\n",
    "    logger.info(f\"loaded {table.num_rows} rows into {table.full_table_id}\")\n",
    "\n",
    "## Airlines Dimension\n",
    "# load to bigquery\n",
    "table_name = f\"{PROJECT_NAME}.{DATASET_NAME}.{TABLE_METADATA['airlines_d']['table_name']}\"\n",
    "schema = TABLE_METADATA['airlines_d']['schema']\n",
    "load_table(airline_df, client, table_name, schema)\n",
    "\n",
    "## Airports Dimension\n",
    "# load to bigquery\n",
    "table_name = f\"{PROJECT_NAME}.{DATASET_NAME}.{TABLE_METADATA['airports_d']['table_name']}\"\n",
    "schema = TABLE_METADATA['airports_d']['schema']\n",
    "load_table(airports_df, client, table_name, schema)\n",
    "\n",
    "## Passengers Dimension\n",
    "# load to bigquery\n",
    "table_name = f\"{PROJECT_NAME}.{DATASET_NAME}.{TABLE_METADATA['passengers_d']['table_name']}\"\n",
    "schema = TABLE_METADATA['passengers_d']['schema']\n",
    "load_table(pass_df, client, table_name, schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. _Load Facts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/deb-projects/airline-data-modeling/venv/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO ][2023-01-06 18:19:17,350][600813873:0030] : loading table: 'electric-glyph-372116.airlines.tickets'\n",
      "[INFO ][2023-01-06 18:19:20,636][600813873:0035] : loaded 4096 rows into electric-glyph-372116:airlines.tickets\n"
     ]
    }
   ],
   "source": [
    "tickets_df = df[['eticket_num', \n",
    "'confirmation', \n",
    "'ticket_date',\n",
    "'passenger.email', # use to lookup sk_pass_id in pass_df\n",
    "'price', \n",
    "'seat', \n",
    "'airline.iata', \n",
    "'origin.iata', \n",
    "'destination.iata'\n",
    "]]\n",
    "\n",
    "tickets_df.rename(columns={\n",
    "  'passenger.email':'email', \n",
    "  'airline.iata':'airline_id', \n",
    "  'origin.iata':'origin_id',\n",
    "  'destination.iata':'dest_id'\n",
    "}, inplace=True)\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  sk_pass_id, \n",
    "  email\n",
    "FROM {PROJECT_NAME}.{DATASET_NAME}.passengers_d\n",
    "\"\"\"\n",
    "pdf = client.query(query).to_dataframe()\n",
    "tickets_df = pd.merge(tickets_df, pdf, on = \"email\").drop(\"email\", axis=1)\n",
    "tickets_df['ticket_date'] = pd.to_datetime(tickets_df['ticket_date'])\n",
    "\n",
    "schema = [\n",
    "  bigquery.SchemaField(\"eticket_num\", \"STRING\", mode=\"REQUIRED\"),\n",
    "  bigquery.SchemaField(\"confirmation\", \"STRING\", mode=\"NULLABLE\"),\n",
    "  bigquery.SchemaField(\"ticket_date\", \"DATE\", mode=\"NULLABLE\"), \n",
    "  bigquery.SchemaField(\"price\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "  bigquery.SchemaField(\"seat\", \"STRING\", mode=\"NULLABLE\"),\n",
    "  bigquery.SchemaField(\"airline_id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "  bigquery.SchemaField(\"origin_id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "  bigquery.SchemaField(\"dest_id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "]\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "  schema=schema, \n",
    "  create_disposition=\"CREATE_IF_NEEDED\",\n",
    "  write_disposition=\"WRITE_TRUNCATE\",\n",
    "  destination_table_description=\"Records for individual passenger tickets\",\n",
    ")\n",
    "\n",
    "table_name = f\"{PROJECT_NAME}.{DATASET_NAME}.tickets\"\n",
    "schema = schema\n",
    "load_table(tickets_df, client, table_name, schema)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eb925e235345ffe75b6938749d5e2df8d24cab43adbaf1e5ac7fd251492b6fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
